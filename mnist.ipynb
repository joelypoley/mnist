{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"../data/train.csv\"\n",
    "EVAL_CSV = \"../data/train.csv\"\n",
    "RECORD_DEFAULTS = [[0]] + [[0.] for _ in range(28*28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing cell.\n",
    "def parse_fn(csv_row):\n",
    "    row_as_tensor = tf.decode_csv(csv_row, record_defaults=RECORD_DEFAULTS)\n",
    "    pixels_in_row = row_as_tensor[1:]\n",
    "    # decode_csv has the batch size as the last dimension\n",
    "    pixels_in_row = tf.transpose(pixels_in_row)\n",
    "    with tf.control_dependencies([tf.assert_equal(tf.shape(pixels_in_row)[1:], [28*28])]):\n",
    "        pixels_in_row = tf.identity(pixels_in_row)\n",
    "    pixels = tf.reshape(pixels_in_row, shape=[-1, 28, 28, 1])\n",
    "    label = row_as_tensor[:1]\n",
    "    label = tf.one_hot(indices=label, depth=10)\n",
    "    features = {\n",
    "        \"pixels\" : pixels\n",
    "    }\n",
    "    \n",
    "    return features, label\n",
    "    \n",
    "def get_input_fn(file_pattern, shuffle=False, batch_size=1, num_epochs=1):\n",
    "    \n",
    "    def input_fn():\n",
    "        #files = tf.data.Dataset.list_files(file_pattern)\n",
    "        dataset = tf.data.TextLineDataset(file_pattern)\n",
    "        dataset = dataset.skip(1)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle(buffer_size=1000)\n",
    "        dataset = dataset.repeat(num_epochs)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        dataset = dataset.map(parse_fn)\n",
    "        \n",
    "\n",
    "        return dataset\n",
    "\n",
    "    return input_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]], shape=(1, 3, 10), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nGNgGCRgz/84BgYGBgYWLHL7rf/9x6Wv+sff5Vw45AK+/73Ai0NO9vzf17445Mwu/v0bgUMu9t/fd6sEscuJX/r3dz4OfQIX//77EIhDUvrv33+4HCpy7t+/Y+w4JFf8/XsEl5zI6b8/fHDIie35+zUWhxxD+t+/+3HJRX74e1gShxz/nb9/A9AFmaC0vyIDAx8uyd//GP6q4rKS4dqteJxy9AQAbI49DkhoNMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEUlEQVR4nL2RvUoDURCFj2IhJDFR0S7401mIW2mjjYIGTBdcsLEWxMYn8BkSiFhaWCk2QsBKsNCwhRBIkweQaJWwixYq31osN7m7C5Y5zZ25350zwx1p9BobhjPZE23U/Ycw/SrnfgN0vi4WU6xwj1F3PZ+AJSwdx9nWIwCnlReA4CAGbwGvVltVptgEbmIz38HhThSf/0K7bME1oGiSCnApSRqXJC1J/o+Bz76JItiXvJ656jakvezAderdttU+MD2onJiPjf4Ws+1f6x8dAU3TptCCurWQ/CvgbUuS5q7gc8Eu3WwDT46zvOK0kj8kuQEAH9HhJtqeDZfSczMJmGsYFuymJ54sVwkJq7PJVY9Wf10bnse4xJV1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAVklEQVR4nGNgGGDA3NvNjFOS898/DmQ+Ez6T0CWT8En6kW0sbsm/u/FI/lqAR5LFEo8dnP/+7SDPQTSSnIwmyYLMkWXEI8nwnwQ7UYD9v392RCumEQAAQVYOdaQtHWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect data.\n",
    "def show_array(a, mode='L', fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a, mode=mode).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "\n",
    "input_fn = get_input_fn(TRAIN_CSV, shuffle=False, batch_size=3)\n",
    "dataset = input_fn()\n",
    "\n",
    "for x in dataset.take(1):\n",
    "    print(x[1])\n",
    "    for arr in x[0]['pixels']:\n",
    "        arr2 = tf.squeeze(arr, axis=2)\n",
    "        show_array(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model.\n",
    "def model_fn(features, labels, mode, params):\n",
    "    layer = features[\"pixels\"]\n",
    "    \n",
    "    layer = tf.layers.Conv2D(filters=6, kernel_size=5, strides=1, padding='valid')(layer)\n",
    "    layer = tf.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid')(layer)\n",
    "    layer = tf.layers.Conv2D(filters=16, kernel_size=5, strides=1, padding='valid')(layer)\n",
    "    layer = tf.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid')(layer)\n",
    "    layer = tf.layers.Dense(units=120, activation=tf.nn.relu)(layer)\n",
    "    layer = tf.layers.Dense(units=84, activation=tf.nn.relu)(layer)\n",
    "    layer = tf.layers.Flatten()(layer)\n",
    "    \n",
    "    logits = tf.layers.Dense(units=10)(layer)\n",
    "    labels = tf.squeeze(labels, axis=[0])\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels, logits=logits)\n",
    "    #loss = tf.Print(loss, [loss], message=\"loss\")\n",
    "    \n",
    "    # Return the appropriate EstimatorSpec based on the mode.\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    predicted_labels = tf.argmax(probabilities, axis=-1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\"predicted_labels\": predicted_labels, \"probabilities\": probabilities}\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "            \"accuracy\" : tf.metrics.accuracy(labels=tf.argmax(labels, axis=-1), predictions=predicted_labels),\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "#         learning_rate = tf.train.exponential_decay(\n",
    "#             learning_rate=1e-5, \n",
    "#             global_step=global_step,\n",
    "#             decay_steps=1,\n",
    "#             decay_rate=1.01,\n",
    "#         )\n",
    "#         optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = params['optimizer']\n",
    "    \n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "    else:\n",
    "        assert False, \"mode must of type tf.estimator.ModeKeys was {}\".format(mode)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12afab410>, '_model_dir': '/var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_master': ''}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz/model.ckpt.\n",
      "INFO:tensorflow:loss = 35.857086, step = 1\n",
      "INFO:tensorflow:global_step/sec: 13.1982\n",
      "INFO:tensorflow:loss = 0.23931092, step = 101 (7.579 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 165 into /var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-12-06:02:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz/model.ckpt-165\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [10/100]\n",
      "INFO:tensorflow:Evaluation [20/100]\n",
      "INFO:tensorflow:Evaluation [30/100]\n",
      "INFO:tensorflow:Evaluation [40/100]\n",
      "INFO:tensorflow:Evaluation [50/100]\n",
      "INFO:tensorflow:Evaluation [60/100]\n",
      "INFO:tensorflow:Evaluation [70/100]\n",
      "INFO:tensorflow:Evaluation [80/100]\n",
      "INFO:tensorflow:Evaluation [90/100]\n",
      "INFO:tensorflow:Evaluation [100/100]\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-12-06:02:48\n",
      "INFO:tensorflow:Saving dict for global step 165: accuracy = 0.96, global_step = 165, loss = 0.15013154\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 165: /var/folders/5h/vl9jlymj4kj7mrt7n0s7yt44p3fd66/T/tmpkJ9wvz/model.ckpt-165\n",
      "INFO:tensorflow:Loss for final step: 0.008905642.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.96, 'global_step': 165, 'loss': 0.15013154}, [])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the right learning rate.\n",
    "# Train and evaulate.\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=get_input_fn(TRAIN_CSV, shuffle=True, batch_size=256, num_epochs=1))\n",
    "eval_spec = tf.estimator.EvalSpec(input_fn=get_input_fn(EVAL_CSV))\n",
    "estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        params={\"optimizer\": tf.train.AdamOptimizer(learning_rate=0.0015)},\n",
    "    )\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2-ven",
   "language": "python",
   "name": "py2-ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
